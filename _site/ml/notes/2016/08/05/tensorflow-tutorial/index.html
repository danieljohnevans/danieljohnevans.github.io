
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Tensorflow Notes</title>
    
    <meta name="author" content="">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Bootstrap styles -->
    <link href="/assets/themes/bootstrap-3/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <!-- Optional theme -->
    <link href="/assets/themes/bootstrap-3/bootstrap/css/bootstrap-theme.min.css" rel="stylesheet">
    <!-- Sticky Footer -->
    <link href="/assets/themes/bootstrap-3/bootstrap/css/bs-sticky-footer.css" rel="stylesheet">
    
    <!-- Custom styles -->
    <link href="/assets/themes/bootstrap-3/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">

    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css"> <!-- font awesome -->

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!-- Update these with your own images
      <link rel="shortcut icon" href="images/favicon.ico">
      <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
      <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
      <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
    -->

    <!-- atom & rss feed -->
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">

  </head>

  <body>
    <div id="wrap">
      <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#jb-navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">danieljohnevans</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="jb-navbar-collapse">
          <ul class="nav navbar-nav navbar-right">
            
            
            


  
    
      
      	
      	<li><a href="/about/">About</a></li>
      	
      
    
  
    
      
      	
      	<li><a href="/archive/">Archive</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/categories/">Categories</a></li>
      	
      
    
  
    
  
    
      
    
  



          </ul>
        </div><!-- /.navbar-collapse -->
      </nav>

      <div class="container">
        
<div class="page-header">
  <h1>Tensorflow Notes </h1>
</div>

<div class="row post-full">
  <div class="col-xs-12">
    <div class="date">
      <span>05 August 2016</span>
    </div>
    <div class="content">
      <p>This is my lab notebook as I work through Google’s Tensorflow tutorial. <a href="https://twitter.com/scott_bot">Scott Weingart</a> turned me onto the idea of maintaining notebooks so that I will be able to quickly reference and explain concepts later. Thanks Scott.</p>

<p>Deep Learning and Google’s Tensorflow are two aspects of machine learning I’ve wanted to play around with for awhile now. I’ve understood neural networks from a conceptual level but never closely examined how they worked. I work through the <a href="https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners">tutorial hosted on Google’s site</a> below :</p>

<h3 id="the-data">The data</h3>

<p>The Tensorflow tutorial draws from the <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a>. This database consists of 60,000 examples (and a training set of 10,000 examples) of handwritten numbers. These digits standardized as 28x28 pixel images. This data is popular because it requires minimal preprocessing and allows researchers a fairly standard dataset in which to tell their hypotheses. It was created by Yann LeCun, Corinna Cortes, and Christopher J.C. Burges.</p>

<p>The Tensorflow tutorial further divides this dataset into 55,000 for examples, 10,000 for a training set, and 5,000 for a validation set.</p>

<h3 id="learning">Learning</h3>

<p>The Tensorflow tutorial employs softmax regression system. I understand a softmax regression as a simple model that classifies available evidence and then teaches based on those classes. In this sense, we create a model that recognizes the numbers 0 through 9 as various classes as a first step in our softmax regression and then as a second step construct a model that teaches based on the available data.</p>

<p>Our model is taught based on pixel intensities. See below :</p>

<p>In essence, certain numbers are more likely to darken certain pixels than others. Simply put, once we determine a pattern, we can train this pattern against new data.</p>

<p>Onto the code:</p>

<p>First import the dataset. To note: in this tutorial, we are using “one-hot vectors.” One-hot vectors are single vector dimensions (each number is represented as 0 or 1). As such, the mnist.train.labels is an array of [55000, 10] floats.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s">"MNIST_data/"</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

</code></pre>
</div>
<p>Let’s walk through this diagram (NOTE : insert expression below)</p>

<ul>
  <li>x = input
    <ul>
      <li>x is flattened into a 784-dimensional vector. Specifically, it’s a 2D tensor of floating-point numbers with a shape of [None, 784]</li>
    </ul>
  </li>
  <li>w = weights
    <ul>
      <li>W follows a similar dimensional pattern but the variable is a modifiable variable based on the training model.</li>
    </ul>
  </li>
  <li>b = bias</li>
  <li>Here is the equation written out : y = softmax(Wx + b)</li>
</ul>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y_</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">()</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
  <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">y_</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">})</span>

  <span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">y_</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">}))</span>

</code></pre>
</div>

<h3 id="conclusions">Conclusions</h3>

    </div>

  
    <ul class="tag_box inline">
      <li><i class="glyphicon glyphicon-open"></i></li>
      
      


  
     
    	<li><a href="/categories.html#ml-ref">
    		ml <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#notes-ref">
    		notes <span>1</span>
    	</a></li>
    
  


    </ul>
    

    
  
    <hr>
    <ul class="pagination">
    
      <li class="prev"><a href="/sdfb/bot/2016/08/04/bacon-bot/" title="Early Modern Bots">&laquo; Previous</a></li>
    
      <li><a href="/archive.html">Archive</a></li>
    
      <li class="next disabled"><a>Next &rarr;</a>
    
    </ul>
    <hr>
    




  </div>
</div>


      </div>

    </div>

    <div id="footer">
          <p>
            <a href="https://www.twitter.com/djohnevans"><i class="fa fa-twitter fa-2x"></i></a>

            <a href="https://github.com/danieljohnevans"><i class="fa fa-github-square fa-2x"></i></a>

            <a href="https://instagram.com/yogurtdanimal"><i class="fa fa-instagram fa-2x"></i></a> 
          </p>  
          <p>
          </p>
          <p> 
            &copy; 2016  with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a> and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a> 
          </p> 
          <p> 
            <a href="http://creativecommons.org/licenses/by/3.0/">All content licensed under CC-BY.</a>
           </p>    
    </div>
    




  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-123-12']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>





    <!-- Latest compiled and minified JavaScript, requires jQuery 1.x (2.x not supported in IE8) -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <script src="/assets/themes/bootstrap-3/bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>

